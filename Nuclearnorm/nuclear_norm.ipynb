{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recovering matrices\n",
    "\n",
    "Most of my research is focused on predicting matrix-valued data ('pairwise learning'). This works by either having features of the rows and columns or by exploiting some kind of structure in the matrix. One particularly appealing type of structure is that a matrix $X$ is low rank, i.e.\n",
    "\n",
    "$$\n",
    "X \\approx UV^\\intercal\\,,\n",
    "$$\n",
    "\n",
    "where both $U$ and $V$ are 'long': they have many rows but few columns. Many large matrices can be modelled as such, since it is assumed that there are only a couple of hidden variables that explain the data. This principle is widely used in unsupervised learning (factorization methods such as PCA and the like) and can be exploited to, for example, find the [topmost relevant items efficiently](https://link.springer.com/article/10.1007/s10618-016-0456-z).\n",
    "\n",
    "One way to find low-rank matrices is by adding the nuclear norm as a matrix regularizer. This could recover a low-rank matrix. Only very recently it finally clicked in my mind how this works. This post is a small technical note on how to use empirical risk minimization to recover matrices, with an emphasis low-rank and positive semi-definite ones. As an illustration, I will show that with some straightforward code, we can obtain a better estimate of a correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using CSV, Statistics, LinearAlgebra, DataFrames\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recovering matrices\n",
    "\n",
    "Suppose we have matrix $Y$ of observations, for example user-item ratings, interaction values between drugs and protein targets, or the adjacency matrix of a food web. If we expect that the values of $Y$ are corrupted or if $Y$ is incomplete, we need to re-estimate $Y$ by a hopefully better matrix $X$. In machine learning, such problems are approached by solving an *empirical risk minimization problem* (ERMP): \n",
    "\n",
    "$$\n",
    "\\min_X l(Y, X) +\\lambda \\cdot h(X)\\,.\n",
    "$$\n",
    "\n",
    "This optimization problem has typically three parts:\n",
    "\n",
    "- a *loss function* $l(\\cdot, \\cdot)$ which quantifies how well the matrix $X$ approximates our observed matrix $Y$;\n",
    "- a *regularization function* $h(\\cdot)$, which we can use to impose some structure on the matrix $X$;\n",
    "- a *regularization parameter* $\\lambda$, a turing switch to adjust the relative trade-off between the two terms above.\n",
    "\n",
    "For the loss function, there are plenty of options, depending on the nature of the data (regression, classification, many outliers...). We will just focus on the vanilla squared loss:\n",
    "\n",
    "$$\n",
    "l(Y, X) = \\sum_{i,j}(Y_{ij}-X_{ij})^2\\,,\n",
    "$$\n",
    "\n",
    "which is most appropriate if the elements of $Y$ are real-valued and meausurement errors are close to normally distributed. Note that if not all the values of $Y$ are observed, we can trivially deal with this by just taking the sum over the sampled values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we only minimize a loss, we will just obtain a matrix $X$ with exactly the same content as $Y$, not particularly exciting! The magic of the regularizer is that it will impose some structure on the learnt matrix $X$. The most basic assumption we can make is that the values of $X$ should not be 'too large', which can be enforced by $L_2$: regularization:\n",
    "\n",
    "$$\n",
    "h_{L_2}(X) = \\sum_{i,j} X_{ij}^2\\,.\n",
    "$$\n",
    "\n",
    "The $L_2$ norm ensures that no value in $X$ can grow too large, as the penalty is proportional to the squared value. The nice thing about this, if that in conjunction with the squared loss, the empirical risk minimization problem yields a closed-form solution. \n",
    "\n",
    "A popular alternative to $L_2$ regularization is by using $L_1$-norm instead:\n",
    "\n",
    "$$\n",
    "h_{L_1}(X) = \\sum_{i,j} |X_{ij}|\\,.\n",
    "$$\n",
    "\n",
    "The $L_1$ norm enforces *sparsity*: many of the values in $X$ will be driven to zero. Additionally, the $L_1$,  regulalizer, in contrast to $L_2$, is also more tolerant to having some larger values in $X$ (linear vs. quadratic penalty).\n",
    "\n",
    "What if, rather than having some demands on the individual values of $X$, we want this matrix to be 'simple' in a more global way? One way how $X$ can be simple, is by searching for an $X$ with a low rank, i.e. one that can be represented by a few dimensions. Is there a simple way to guide $X$ towards having a low rank? Yes! This can be done by considering the nuclear norm:\n",
    "\n",
    "$$\n",
    "||X||_\\star = \\sqrt{\\text{tr}(X^\\intercal X)}\\,,\n",
    "$$\n",
    "\n",
    "which leads to a regularizer:\n",
    "\n",
    "$$\n",
    "h_\\text{nucl}(X) = \\text{tr}(X^\\intercal X)\\,.\n",
    "$$\n",
    "\n",
    "So the trace (taking the sum of the diagonal values of a matrix) apparently holds the key to finding low-rank matrices. The reason is quite an interesting exercise in linear algebra. Note that the [singular value decompostion](https://en.wikipedia.org/wiki/Singular_value_decomposition) of $X$ is written as:\n",
    "\n",
    "$$\n",
    "X = \\sum_k\\sigma_k\\mathbf{u}_k\\mathbf{v}^\\intercal_k\\,,\n",
    "$$\n",
    "\n",
    "with $\\mathbf{u}_1, \\mathbf{u}_2,\\ldots$ and $\\mathbf{v}_1, \\mathbf{u}_2,\\ldots$ two sets of orthonormal eigenvectors and $\\sigma_1, \\sigma_2,\\ldots$ the eigenvalues of $X^\\intercal X$. If $X$ is low rank, this means that many of these eigenvalues are zero. Note that these eigenvalues are all non-negative reals if $X$ is real-valued. The trace of a matrix is equal to the sum of its eigenvalues, hence we can write\n",
    "\n",
    "$$\n",
    "\\text{tr}(X^\\intercal X) = \\sum_k \\sigma_k = \\sum_k |\\sigma_k|\\,.\n",
    "$$\n",
    "\n",
    "This means that the trace will place an $L_2$ regularization on the eigenvalues. Large values of the regularization parameter $\\lambda$ will drive many of the eigenvalues to zero, ensuring that $X$ will be low rank[^UV].\n",
    "\n",
    "[^UV]: You might wonder why not simply reformulate the problem by substituting $X$ by $UV^\\intercal$ and minimize the objective w.r.t. $U$ and $V$. In this case, the problem is no longer convex and has no longer an unique solution (swapping any corresponding of $U$ and the corresponding ones in $V$ yields the same objective value). The optimization problem will no longer have a single minimum is is thus harder to solve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illustration: approximating a covariance matrix\n",
    "\n",
    "Let us illustrate this on a related problem: re-estimating a covariance matrix[^kernel]. Similar to the ERMP of above, we have a covariance matrix $\\Sigma$ which we want to approximate by a matrix $S$ (for example because $\\Sigma$ is subjected to high variance during estimation). The problem becomes:\n",
    "\n",
    "$$\n",
    "\\min_{S\\succeq 0} l(\\Sigma, S) + \\lambda \\cdot h(S)\\,.\n",
    "$$\n",
    "\n",
    "We restrict ourselves to searching in the [positive semi-definite](https://en.wikipedia.org/wiki/Definiteness_of_a_matrix) (PSD) cone ($S\\succeq 0$). Since covariance matrices are PSD, all eigenvalues are non-zero.\n",
    "\n",
    "We will try this out on the [wines dataset](https://archive.ics.uci.edu/ml/datasets/wine), a small dataset containing 13 chemical and physical characteristics of several wines. We will first compute the covariance matrix and subsequently re-estimate this matrix, penalizing the $L_2$-, $L_1$ and nuclear norm.\n",
    "\n",
    "[^kernel]: A related problem would be kernel learning, where the goal is to find a good [kernel](https://en.wikipedia.org/wiki/Kernel_method) matrix describing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>variable</th><th>mean</th><th>min</th><th>median</th><th>max</th><th>nunique</th><th>nmissing</th><th>eltype</th></tr><tr><th></th><th>Symbol</th><th>Float64</th><th>Real</th><th>Float64</th><th>Real</th><th>Nothing</th><th>Int64</th><th>DataType</th></tr></thead><tbody><p>13 rows × 8 columns</p><tr><th>1</th><td>Alcohol</td><td>1.9382</td><td>1</td><td>2.0</td><td>3</td><td></td><td>0</td><td>Int64</td></tr><tr><th>2</th><td>Malic acid</td><td>13.0006</td><td>11.03</td><td>13.05</td><td>14.83</td><td></td><td>0</td><td>Float64</td></tr><tr><th>3</th><td>Ash</td><td>2.33635</td><td>0.74</td><td>1.865</td><td>5.8</td><td></td><td>0</td><td>Float64</td></tr><tr><th>4</th><td>Alcalinity of ash</td><td>2.36652</td><td>1.36</td><td>2.36</td><td>3.23</td><td></td><td>0</td><td>Float64</td></tr><tr><th>5</th><td>Magnesium</td><td>19.4949</td><td>10.6</td><td>19.5</td><td>30.0</td><td></td><td>0</td><td>Float64</td></tr><tr><th>6</th><td>Total phenols</td><td>99.7416</td><td>70</td><td>98.0</td><td>162</td><td></td><td>0</td><td>Int64</td></tr><tr><th>7</th><td>Flavanoids</td><td>2.29511</td><td>0.98</td><td>2.355</td><td>3.88</td><td></td><td>0</td><td>Float64</td></tr><tr><th>8</th><td>Nonflavanoid phenols</td><td>2.02927</td><td>0.34</td><td>2.135</td><td>5.08</td><td></td><td>0</td><td>Float64</td></tr><tr><th>9</th><td>Proanthocyanins</td><td>0.361854</td><td>0.13</td><td>0.34</td><td>0.66</td><td></td><td>0</td><td>Float64</td></tr><tr><th>10</th><td>Color intensity</td><td>1.5909</td><td>0.41</td><td>1.555</td><td>3.58</td><td></td><td>0</td><td>Float64</td></tr><tr><th>11</th><td>Hue</td><td>5.05809</td><td>1.28</td><td>4.69</td><td>13.0</td><td></td><td>0</td><td>Float64</td></tr><tr><th>12</th><td>OD280/OD315 of diluted wines</td><td>0.957449</td><td>0.48</td><td>0.965</td><td>1.71</td><td></td><td>0</td><td>Float64</td></tr><tr><th>13</th><td>Proline</td><td>2.61169</td><td>1.27</td><td>2.78</td><td>4.0</td><td></td><td>0</td><td>Float64</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& variable & mean & min & median & max & nunique & nmissing & eltype\\\\\n",
       "\t\\hline\n",
       "\t& Symbol & Float64 & Real & Float64 & Real & Nothing & Int64 & DataType\\\\\n",
       "\t\\hline\n",
       "\t1 & Alcohol & 1.9382 & 1 & 2.0 & 3 &  & 0 & Int64 \\\\\n",
       "\t2 & Malic acid & 13.0006 & 11.03 & 13.05 & 14.83 &  & 0 & Float64 \\\\\n",
       "\t3 & Ash & 2.33635 & 0.74 & 1.865 & 5.8 &  & 0 & Float64 \\\\\n",
       "\t4 & Alcalinity of ash & 2.36652 & 1.36 & 2.36 & 3.23 &  & 0 & Float64 \\\\\n",
       "\t5 & Magnesium & 19.4949 & 10.6 & 19.5 & 30.0 &  & 0 & Float64 \\\\\n",
       "\t6 & Total phenols & 99.7416 & 70 & 98.0 & 162 &  & 0 & Int64 \\\\\n",
       "\t7 & Flavanoids & 2.29511 & 0.98 & 2.355 & 3.88 &  & 0 & Float64 \\\\\n",
       "\t8 & Nonflavanoid phenols & 2.02927 & 0.34 & 2.135 & 5.08 &  & 0 & Float64 \\\\\n",
       "\t9 & Proanthocyanins & 0.361854 & 0.13 & 0.34 & 0.66 &  & 0 & Float64 \\\\\n",
       "\t10 & Color intensity & 1.5909 & 0.41 & 1.555 & 3.58 &  & 0 & Float64 \\\\\n",
       "\t11 & Hue & 5.05809 & 1.28 & 4.69 & 13.0 &  & 0 & Float64 \\\\\n",
       "\t12 & OD280/OD315 of diluted wines & 0.957449 & 0.48 & 0.965 & 1.71 &  & 0 & Float64 \\\\\n",
       "\t13 & Proline & 2.61169 & 1.27 & 2.78 & 4.0 &  & 0 & Float64 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "13×8 DataFrame. Omitted printing of 3 columns\n",
       "│ Row │ variable                     │ mean     │ min   │ median  │ max   │\n",
       "│     │ \u001b[90mSymbol\u001b[39m                       │ \u001b[90mFloat64\u001b[39m  │ \u001b[90mReal\u001b[39m  │ \u001b[90mFloat64\u001b[39m │ \u001b[90mReal\u001b[39m  │\n",
       "├─────┼──────────────────────────────┼──────────┼───────┼─────────┼───────┤\n",
       "│ 1   │ Alcohol                      │ 1.9382   │ 1     │ 2.0     │ 3     │\n",
       "│ 2   │ Malic acid                   │ 13.0006  │ 11.03 │ 13.05   │ 14.83 │\n",
       "│ 3   │ Ash                          │ 2.33635  │ 0.74  │ 1.865   │ 5.8   │\n",
       "│ 4   │ Alcalinity of ash            │ 2.36652  │ 1.36  │ 2.36    │ 3.23  │\n",
       "│ 5   │ Magnesium                    │ 19.4949  │ 10.6  │ 19.5    │ 30.0  │\n",
       "│ 6   │ Total phenols                │ 99.7416  │ 70    │ 98.0    │ 162   │\n",
       "│ 7   │ Flavanoids                   │ 2.29511  │ 0.98  │ 2.355   │ 3.88  │\n",
       "│ 8   │ Nonflavanoid phenols         │ 2.02927  │ 0.34  │ 2.135   │ 5.08  │\n",
       "│ 9   │ Proanthocyanins              │ 0.361854 │ 0.13  │ 0.34    │ 0.66  │\n",
       "│ 10  │ Color intensity              │ 1.5909   │ 0.41  │ 1.555   │ 3.58  │\n",
       "│ 11  │ Hue                          │ 5.05809  │ 1.28  │ 4.69    │ 13.0  │\n",
       "│ 12  │ OD280/OD315 of diluted wines │ 0.957449 │ 0.48  │ 0.965   │ 1.71  │\n",
       "│ 13  │ Proline                      │ 2.61169  │ 1.27  │ 2.78    │ 4.0   │"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines = CSV.read(\"wines.csv\")\n",
    "variables = String.(names(wines))\n",
    "describe(wines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use $\\Sigma$ to denote the unbiased estimator of the covariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13×13 Array{Float64,2}:\n",
       "  0.600679   -0.206515    0.379039   …  -0.109368    -0.433737   \n",
       " -0.206515    0.659062    0.0856113     -0.0133134    0.0416978  \n",
       "  0.379039    0.0856113   1.24802       -0.143326    -0.292447   \n",
       " -0.0105554   0.0471152   0.050277      -0.00468215   0.000761836\n",
       "  1.34036    -0.841093    1.07633       -0.209118    -0.656234   \n",
       " -2.3155      3.13988    -0.87078    …   0.180851     0.669308   \n",
       " -0.348835    0.146887   -0.234338       0.0620389    0.311021   \n",
       " -0.656091    0.192033   -0.45863        0.124082     0.558262   \n",
       "  0.0471774  -0.0157543   0.0407334     -0.00747118  -0.0444692  \n",
       " -0.221413    0.0635175  -0.141147       0.0386646    0.210933   \n",
       "  0.477339    1.02828     0.644838   …  -0.276506    -0.705813   \n",
       " -0.109368   -0.0133134  -0.143326       0.052245     0.0917662  \n",
       " -0.433737    0.0416978  -0.292447       0.0917662    0.504086   "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert DataFrame to Matrix\n",
    "X = convert(Matrix, wines)\n",
    "Σ = cov(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a [simple gradient descent](https://michielstock.github.io/ConvexSummary/) to solve the ERMP. During the gradient updates, it is possible that $S$ is no longer positive semi-definite. For this reason, we will have to project back in the positive semi-definite cone in every step. This can be done by setting negative eigenvalues to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "projectSPDcone! (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function projectSPDcone!(S)\n",
    "    vals, vectors = eigen(S)\n",
    "    vals[vals .< 0.0] .= 0.0\n",
    "    S .= vectors * Diagonal(vals) * vectors'\n",
    "    return S\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can use soft-thresholding to set very small values to zero. This is an easy way to make sparse solutions possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "softthreshold! (generic function with 2 methods)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function softthreshold!(X, tol::Real=1e-4)\n",
    "    X[abs.(X) .< tol] .= 0.0\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need the gradient of loss and regularization functions. These can be computed using automatic differentiation methods, but since the functions are so simple, let's provide them explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "∇ls (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇ls(Y, X) = 2(X .- Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "∇nucl (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇L₂(X) = 2X\n",
    "∇L₁(X) = sign.(X)\n",
    "∇nucl(S) = sign.(Diagonal(S))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that here the nuclear regularization is directly on the matrix, since it is already symmetric and PSD.\n",
    "\n",
    "Putting this all together, we have obtain a general gradient descent function to approximate PSD matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PSDapprox (generic function with 2 methods)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function PSDapprox(Σ::AbstractArray, ∇norm::Function, ∇loss=∇ls;\n",
    "                λ=1.0, stepsize=1e-3, maxitter=20_000, tol=1e-4)\n",
    "    S = copy(Σ)\n",
    "    ΔS = similar(S)\n",
    "    for i in 1:maxitter\n",
    "        # compute gradient of loss + norm\n",
    "        ΔS .= ∇ls(Σ, S) + λ * ∇norm(S)\n",
    "        # stop if the gradient is small\n",
    "        if norm(ΔS) < tol\n",
    "            break\n",
    "        end\n",
    "        S -= stepsize * ΔS\n",
    "        # project back into the SPD cone\n",
    "        S .= projectSPDcone!(S)\n",
    "        # soft thresholding\n",
    "        softthreshold!(S, tol)\n",
    "    end\n",
    "    S\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try for the different regularizers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13×13 Array{Float64,2}:\n",
       "  0.500566    -0.172096    0.315866   …  -0.0911396   -0.361448   \n",
       " -0.172096     0.549219    0.0713428     -0.0110945    0.0347482  \n",
       "  0.315866     0.0713428   1.04001       -0.119438    -0.243706   \n",
       " -0.00879621   0.0392626   0.0418975     -0.0039018    0.000634863\n",
       "  1.11697     -0.700911    0.896943      -0.174265    -0.546862   \n",
       " -1.92958      2.61657    -0.72565    …   0.150709     0.557757   \n",
       " -0.290696     0.122406   -0.195281       0.0516991    0.259184   \n",
       " -0.546742     0.160028   -0.382192       0.103402     0.465219   \n",
       "  0.0393145   -0.0131286   0.0339445     -0.00622598  -0.0370577  \n",
       " -0.184511     0.0529313  -0.117623       0.0322205    0.175777   \n",
       "  0.397783     0.856902    0.537365   …  -0.230422    -0.588177   \n",
       " -0.0911396   -0.0110945  -0.119438       0.0435375    0.0764719  \n",
       " -0.361448     0.0347482  -0.243706       0.0764719    0.420072   "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SL₂ = PSDapprox(Σ, ∇L₂, λ=2e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13×13 Array{Float64,2}:\n",
       "  0.502745   -0.105621      0.279187     …  -0.0208615    -0.335675  \n",
       " -0.105621    0.55945       0.000142351      0.0           0.0       \n",
       "  0.279187    0.000142351   1.14803         -0.0441496    -0.192586  \n",
       "  0.0         0.0           0.0             -0.000107562   0.0       \n",
       "  1.23978    -0.741346      0.97629         -0.10587      -0.555687  \n",
       " -2.2155      3.03988      -0.77078      …   0.0808711     0.569311  \n",
       " -0.249459    0.0466174    -0.134382         0.0           0.211606  \n",
       " -0.554226    0.0928404    -0.358497         0.0137052     0.456512  \n",
       "  0.0         0.0           0.0             -0.000149592   0.0       \n",
       " -0.121912    0.0          -0.0411828        0.0           0.111401  \n",
       "  0.376425    0.927887      0.544773     …  -0.171415     -0.604954  \n",
       " -0.0208615   0.0          -0.0441496        0.0162355     0.00255751\n",
       " -0.335675    0.0          -0.192586         0.00255751    0.405906  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SL₁ = PSDapprox(Σ, ∇L₁, λ=2e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13×13 Array{Float64,2}:\n",
       "  0.523474   -0.2018      0.378216   …  -0.102672    -0.425452  \n",
       " -0.2018      0.560289    0.0853282     -0.0146486    0.0434516 \n",
       "  0.378216    0.0853282   1.14846       -0.138243    -0.292814  \n",
       "  0.0         0.0474372   0.0479655     -0.00677665   0.00514546\n",
       "  1.33877    -0.841296    1.07649       -0.209159    -0.656809  \n",
       " -2.31547     3.1399     -0.870777   …   0.180832     0.669327  \n",
       " -0.360782    0.143824   -0.234054       0.0621105    0.307935  \n",
       " -0.642777    0.195738   -0.459109       0.121481     0.562478  \n",
       "  0.0496407  -0.0149893   0.0401001     -0.00982623  -0.0395298 \n",
       " -0.223001    0.062717   -0.141305       0.0383765    0.21024   \n",
       "  0.476298    1.02801     0.645162   …  -0.273265    -0.706216  \n",
       " -0.102672   -0.0146486  -0.138243       0.0302173    0.0936902 \n",
       " -0.425452    0.0434516  -0.292814       0.0936902    0.407482  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Snucl = PSDapprox(Σ, ∇nucl, λ=2e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If these matrices are compared with the original matrix $\\Sigma$, you notice that the values have been shrunken by the regularization: we we sacrifice unbiasedness for a large drop in variance! As promised, the coviance matrix obtained by using $L_1$ regularization is quite sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity SL₂: 0.0\n",
      "sparsity SL₁: 0.2603550295857988\n",
      "sparsity Snucl: 0.011834319526627219\n"
     ]
    }
   ],
   "source": [
    "println(\"sparsity SL₂: $(mean(SL₂.==0))\")\n",
    "println(\"sparsity SL₁: $(mean(SL₁.==0))\")\n",
    "println(\"sparsity Snucl: $(mean(Snucl.==0))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A look at the spectrum of all matrices shows that the nuclear norm results in low-rank matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spectrum (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrum(S) = sort(real(eigvals(S)), rev=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip6500\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polygon clip-path=\"url(#clip6500)\" points=\"\n",
       "0,1600 2400,1600 2400,0 0,0 \n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip6501\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polygon clip-path=\"url(#clip6500)\" points=\"\n",
       "288.452,1440.48 2321.26,1440.48 2321.26,125.984 288.452,125.984 \n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip6502\">\n",
       "    <rect x=\"288\" y=\"125\" width=\"2034\" height=\"1315\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip6502)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  585.702,1440.48 585.702,125.984 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6502)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  985.232,1440.48 985.232,125.984 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6502)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1384.76,1440.48 1384.76,125.984 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6502)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1784.29,1440.48 1784.29,125.984 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6502)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2183.82,1440.48 2183.82,125.984 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6502)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  288.452,1262.8 2321.26,1262.8 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6502)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  288.452,907.429 2321.26,907.429 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6502)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  288.452,552.061 2321.26,552.061 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6502)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  288.452,196.692 2321.26,196.692 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  288.452,1440.48 2321.26,1440.48 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  288.452,1440.48 288.452,125.984 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  585.702,1440.48 585.702,1420.77 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  985.232,1440.48 985.232,1420.77 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1384.76,1440.48 1384.76,1420.77 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1784.29,1440.48 1784.29,1420.77 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2183.82,1440.48 2183.82,1420.77 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  288.452,1262.8 318.944,1262.8 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  288.452,907.429 318.944,907.429 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  288.452,552.061 318.944,552.061 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  288.452,196.692 318.944,196.692 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip6500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 585.702, 1494.48)\" x=\"585.702\" y=\"1494.48\">2.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 985.232, 1494.48)\" x=\"985.232\" y=\"1494.48\">5.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1384.76, 1494.48)\" x=\"1384.76\" y=\"1494.48\">7.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1784.29, 1494.48)\" x=\"1784.29\" y=\"1494.48\">10.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 2183.82, 1494.48)\" x=\"2183.82\" y=\"1494.48\">12.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 155.471, 1286.53)\" x=\"155.471\" y=\"1286.53\">10</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:38px; text-anchor:start;\" transform=\"rotate(0, 208.996, 1259.12)\" x=\"208.996\" y=\"1259.12\">-</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:38px; text-anchor:start;\" transform=\"rotate(0, 231.836, 1259.12)\" x=\"231.836\" y=\"1259.12\">4 </text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 155.471, 931.157)\" x=\"155.471\" y=\"931.157\">10</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:38px; text-anchor:start;\" transform=\"rotate(0, 208.996, 903.747)\" x=\"208.996\" y=\"903.747\">-</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:38px; text-anchor:start;\" transform=\"rotate(0, 231.836, 903.747)\" x=\"231.836\" y=\"903.747\">2 </text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 178.311, 575.788)\" x=\"178.311\" y=\"575.788\">10</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:38px; text-anchor:start;\" transform=\"rotate(0, 231.836, 548.378)\" x=\"231.836\" y=\"548.378\">0 </text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 178.311, 220.42)\" x=\"178.311\" y=\"220.42\">10</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:38px; text-anchor:start;\" transform=\"rotate(0, 231.836, 193.009)\" x=\"231.836\" y=\"193.009\">2 </text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:84px; text-anchor:middle;\" transform=\"rotate(0, 1304.86, 73.2)\" x=\"1304.86\" y=\"73.2\">Spectrum</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:66px; text-anchor:middle;\" transform=\"rotate(0, 1304.86, 1590.4)\" x=\"1304.86\" y=\"1590.4\">Eigenvalue number</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:66px; text-anchor:middle;\" transform=\"rotate(-90, 166.052, 783.233)\" x=\"166.052\" y=\"783.233\">Value</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip6502)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  345.984,141.503 505.796,362.055 665.608,418.111 825.42,507.062 985.232,559.164 1145.04,634.761 1304.86,695.64 1464.67,719.788 1624.48,735.869 1784.29,776.764 \n",
       "  1944.1,810.832 2103.92,850.911 2263.73,922.629 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6502)\" style=\"stroke:#e26f46; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  345.984,155.572 505.796,376.124 665.608,432.18 825.42,521.131 985.232,573.233 1145.04,648.83 1304.86,709.709 1464.67,733.857 1624.48,749.938 1784.29,790.833 \n",
       "  1944.1,824.901 2103.92,864.98 2263.73,936.699 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6502)\" style=\"stroke:#3da44d; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  345.984,141.55 505.796,363.797 665.608,421.293 825.42,524.36 985.232,562.494 1145.04,632.858 1304.86,696.066 1464.67,725.326 1624.48,735.346 1784.29,824.831 \n",
       "  1944.1,919.064 2103.92,1114.89 2263.73,1.7892e+39 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6502)\" style=\"stroke:#c271d2; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  345.984,141.541 505.796,362.715 665.608,419.484 825.42,511.486 985.232,568.121 1145.04,661.372 1304.86,774.761 1464.67,883.154 1624.48,1489.69 1784.29,3258.64 \n",
       "  1944.1,3757.18 2103.92,1.7892e+39 2263.73,1.7892e+39 \n",
       "  \"/>\n",
       "<polygon clip-path=\"url(#clip6500)\" points=\"\n",
       "1888.88,511.904 2249.26,511.904 2249.26,209.504 1888.88,209.504 \n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip6500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1888.88,511.904 2249.26,511.904 2249.26,209.504 1888.88,209.504 1888.88,511.904 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6500)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1912.88,269.984 2056.88,269.984 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip6500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 2080.88, 287.484)\" x=\"2080.88\" y=\"287.484\">?</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip6500)\" style=\"stroke:#e26f46; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  1912.88,330.464 2056.88,330.464 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip6500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 2080.88, 347.964)\" x=\"2080.88\" y=\"347.964\">SLâ</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip6500)\" style=\"stroke:#3da44d; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  1912.88,390.944 2056.88,390.944 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip6500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 2080.88, 408.444)\" x=\"2080.88\" y=\"408.444\">SLâ</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip6500)\" style=\"stroke:#c271d2; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  1912.88,451.424 2056.88,451.424 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip6500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 2080.88, 468.924)\" x=\"2080.88\" y=\"468.924\">Snucl</text>\n",
       "</g>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(spectrum(Σ), label=\"Σ\")\n",
    "plot!(spectrum(SL₂), label=\"SL₂\", lw=2)\n",
    "plot!(spectrum(SL₁), label=\"SL₁\", lw=2)\n",
    "plot!(spectrum(Snucl), label=\"Snucl\", lw=2)\n",
    "yaxis!(\"Value\", :log10)\n",
    "xaxis!(\"Eigenvalue number\")\n",
    "ylims!(1e-5, 250)\n",
    "title!(\"Spectrum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the rank explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank Σ: 13\n",
      "rank SL₂: 13\n",
      "rank SL₁: 12\n",
      "rank Snucl: 8\n"
     ]
    }
   ],
   "source": [
    "println(\"rank Σ: $(rank(Σ, rtol=1e-6))\")\n",
    "println(\"rank SL₂: $(rank(SL₂, rtol=1e-6))\")\n",
    "println(\"rank SL₁: $(rank(SL₁, rtol=1e-6))\")\n",
    "println(\"rank Snucl: $(rank(Snucl, rtol=1e-6))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As claimed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Many machine learning problems can be posed as recovering a matrix (e.g. edge prediction in a graph, collaborative filtering, image inpainting...). Emperical risk minization is a general framework to think about such problems, where the regualarization penalty can be used to impose some structure on the learned matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
